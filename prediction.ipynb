{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e74d383-d8ba-4935-9f1c-27c9be2a98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "import os\n",
    "\n",
    "\n",
    "import time\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import joblib\n",
    "import glob\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from boruta import BorutaPy\n",
    "from copy import deepcopy\n",
    "import shap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c2c7b-62ae-4472-b570-485ce01bebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the input\n",
    "\n",
    "land_name1 = \"global_SSP2_RCP45_2025\"\n",
    "mypath_land1 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+land_name1+'/5km.csv'\n",
    "land_select1 = pd.read_csv(mypath_land1)\n",
    "land_select1.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "\n",
    "\n",
    "climate_name1 = \"ssp245_2011_2040\"\n",
    "mypath_climate1 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+climate_name1+'/5km.csv'\n",
    "climate_select1 = pd.read_csv(mypath_climate1)\n",
    "climate_select1.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "\n",
    "\n",
    "df_2011_2040 = pd.merge(climate_select1, land_select1, on='id')\n",
    "\n",
    "land_name2 = \"global_SSP2_RCP45_2055\"\n",
    "mypath_land2 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+land_name2+'/5km.csv'\n",
    "land_select2 = pd.read_csv(mypath_land2)\n",
    "land_select2.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "\n",
    "\n",
    "climate_name2 = \"ssp245_2041_2070\"\n",
    "mypath_climate2 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+climate_name2+'/5km.csv'\n",
    "climate_select2 = pd.read_csv(mypath_climate2)\n",
    "climate_select2.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "\n",
    "\n",
    "df_2041_2070 = pd.merge(climate_select2, land_select2, on='id')\n",
    "\n",
    "land_name3 = \"global_SSP2_RCP45_2085\"\n",
    "mypath_land3 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+land_name3+'/5km.csv'\n",
    "land_select3 = pd.read_csv(mypath_land3)\n",
    "land_select3.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "\n",
    "\n",
    "climate_name3 = \"ssp245_2071_2100\"\n",
    "mypath_climate3 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+climate_name3+'/5km.csv'\n",
    "climate_select3 = pd.read_csv(mypath_climate3)\n",
    "climate_select3.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "\n",
    "\n",
    "df_2071_2100 = pd.merge(climate_select3, land_select3, on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee21ea4-7487-465f-aea5-e617b6f3f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trees and get output\n",
    "\n",
    "\n",
    "sp_rarefied_name_list = ['San','Rub','Rec','Pro','Mex','Maz','Lon','Lec','Ind','Ger','Dim']\n",
    "\n",
    "buffer_name_list = ['b_05']#,'b_50','b_100']\n",
    "\n",
    "rarefied_name_list = ['']#'_10','']\n",
    "\n",
    "count_num = 0\n",
    "\n",
    "num_runs = 50\n",
    "\n",
    "\n",
    "scenario = 'SSP5_RCP85'\n",
    "scenario2 = 'ssp585'\n",
    "\n",
    "\n",
    "for rarefied_name in rarefied_name_list:\n",
    "    for buffer_name in buffer_name_list:\n",
    "        for bug_name in sp_rarefied_name_list:\n",
    "            land_name1 = \"global_\"+scenario+\"_2025\"\n",
    "            mypath_land1 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+land_name1+'/5km.csv'\n",
    "            land_select1 = pd.read_csv(mypath_land1)\n",
    "            land_select1.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "            #print(land_select1.keys())\n",
    "            \n",
    "\n",
    "\n",
    "            climate_name1 = scenario2+\"_2011_2040\"\n",
    "            mypath_climate1 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+climate_name1+'/5km.csv'\n",
    "            climate_select1 = pd.read_csv(mypath_climate1)\n",
    "            climate_select1.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "            #print(climate_select1.keys())\n",
    "         \n",
    "\n",
    "\n",
    "            df_2011_2040 = pd.merge(climate_select1, land_select1, on='id')\n",
    "\n",
    "            land_name2 = \"global_\"+scenario+\"_2055\"\n",
    "            mypath_land2 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+land_name2+'/5km.csv'\n",
    "            land_select2 = pd.read_csv(mypath_land2)\n",
    "            land_select2.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "            #print(land_select2.keys())\n",
    "\n",
    "\n",
    "\n",
    "            climate_name2 = scenario2+\"_2041_2070\"\n",
    "            mypath_climate2 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+climate_name2+'/5km.csv'\n",
    "            climate_select2 = pd.read_csv(mypath_climate2)\n",
    "            climate_select2.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "            #print(climate_select2.keys())\n",
    "\n",
    "\n",
    "\n",
    "            df_2041_2070 = pd.merge(climate_select2, land_select2, on='id')\n",
    "\n",
    "            land_name3 = \"global_\"+scenario+\"_2085\"\n",
    "            mypath_land3 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+land_name3+'/5km.csv'\n",
    "            land_select3 = pd.read_csv(mypath_land3)\n",
    "            land_select3.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "            #print(land_select3.keys())\n",
    "\n",
    "\n",
    "\n",
    "            climate_name3 = scenario2+\"_2071_2100\"\n",
    "            mypath_climate3 = '/Users/huangliting/Desktop/kissing_bugs_stats/future_reprojection/'+climate_name3+'/5km.csv'\n",
    "            climate_select3 = pd.read_csv(mypath_climate3)\n",
    "            climate_select3.drop(columns=['Unnamed: 0','left', 'top', 'right', 'bottom'], inplace=True)\n",
    "            #print(climate_select3.keys())\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            df_2071_2100 = pd.merge(climate_select3, land_select3, on='id')\n",
    "            \n",
    "            background_data= df_2011_2040.loc[~df_2011_2040['NFFD'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['water'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['cropland'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['permanent_snow_ice'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['barren'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['urban'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['grassland'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['forest'].isnull()].copy()\n",
    "            df_2011_2040 = background_data.copy()\n",
    "            id_list_2011_2040 = df_2011_2040['id']\n",
    "\n",
    "\n",
    "            background_data= df_2041_2070.loc[~df_2041_2070['NFFD'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['water'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['cropland'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['permanent_snow_ice'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['barren'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['urban'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['grassland'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['forest'].isnull()].copy()\n",
    "            df_2041_2070 = background_data.copy()\n",
    "            id_list_2041_2070 = df_2041_2070['id']\n",
    "\n",
    "            background_data= df_2071_2100.loc[~df_2071_2100['NFFD'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['water'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['cropland'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['permanent_snow_ice'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['barren'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['urban'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['grassland'].isnull()].copy()\n",
    "            background_data = background_data.loc[~background_data['forest'].isnull()].copy()\n",
    "            df_2071_2100 = background_data.copy()\n",
    "            id_list_2071_2100 = df_2071_2100['id']\n",
    "            \n",
    "\n",
    "            \n",
    "            grid_name = '5'\n",
    "            name_for_saving = bug_name+rarefied_name+'_g'+grid_name+'_'+buffer_name\n",
    "            \n",
    "            predict_list_2011_2040 = np.array([]) #record prediction of north america\n",
    "            predict_list_2041_2070 = np.array([]) #record prediction of north america\n",
    "            predict_list_2071_2100 = np.array([]) #record prediction of north america\n",
    "            \n",
    "            \n",
    "            count_num = 0\n",
    "            \n",
    "            while count_num < num_runs:\n",
    "\n",
    "                \n",
    "\n",
    "                save_tree_dir = '/Users/huangliting/Desktop/kissing_bugs_stats/trees/'+name_for_saving\n",
    "                tree_filename = save_tree_dir+'/'+name_for_saving+'_'+str(count_num)+'iters.sav'\n",
    "                this_forest = joblib.load(tree_filename)\n",
    "                \n",
    "                dictionary_path = save_tree_dir + '/test'+name_for_saving+'_dictionary_'+str(num_runs)+'iters.pickle'                \n",
    "                with open(dictionary_path, 'rb') as handle:\n",
    "                    this_dictionary = pickle.load(handle)\n",
    "                \n",
    "\n",
    "                \n",
    "                df_2011_2040 = df_2011_2040[this_dictionary['x_label']]\n",
    "                prediction_2011_2040 = this_forest.predict(df_2011_2040.copy())\n",
    "                predict_list_2011_2040 = np.append(predict_list_2011_2040,prediction_2011_2040)\n",
    "                \n",
    "                \n",
    "                df_2041_2070 = df_2041_2070[this_dictionary['x_label']]\n",
    "                prediction_2041_2070 = this_forest.predict(df_2041_2070.copy())\n",
    "                predict_list_2041_2070 = np.append(predict_list_2041_2070,prediction_2041_2070)\n",
    "                \n",
    "                df_2071_2100 = df_2071_2100[this_dictionary['x_label']]\n",
    "                prediction_2071_2100 = this_forest.predict(df_2071_2100.copy())\n",
    "                predict_list_2071_2100 = np.append(predict_list_2071_2100,prediction_2071_2100)\n",
    "                \n",
    "\n",
    "                \n",
    "                count_num = count_num+1\n",
    "                \n",
    "            \"\"\"\n",
    "            save prediction\n",
    "            \"\"\"\n",
    "\n",
    "            #obtain average prediction list\n",
    "            testing_group_size_pre = len(df_2011_2040['MSP'])\n",
    "            prediction_final_list_2011_2040 = np.mean(predict_list_2011_2040.reshape(num_runs, testing_group_size_pre), axis=0)\n",
    "\n",
    "            # initialize data of lists.\n",
    "            final_list_data_f_2011_2040 = {'id': id_list_2011_2040,'prediction': prediction_final_list_2011_2040}\n",
    "\n",
    "            # Create DataFrame\n",
    "            dataframe_fial_prediction_2011_2040 = pd.DataFrame(final_list_data_f_2011_2040)\n",
    "            \"\"\"change_name\"\"\"\n",
    "            #create a directory for storing the trees\n",
    "            pre_dir_2011_2040 = '/Users/huangliting/Desktop/kissing_bugs_stats/predictions/'+scenario2+'_2011_2040_'+name_for_saving\n",
    "\n",
    "\n",
    "            if not os.path.exists(pre_dir_2011_2040):\n",
    "                os.makedirs(pre_dir_2011_2040)\n",
    "\n",
    "\n",
    "            dataframe_fial_prediction_2011_2040.to_csv( pre_dir_2011_2040+'/'+name_for_saving+'_'+str(num_runs)+'iters.csv')\n",
    "            \n",
    "            \"\"\"\n",
    "            save prediction\n",
    "            \"\"\"\n",
    "\n",
    "            #obtain average prediction list\n",
    "            testing_group_size_pre = len(df_2041_2070['MSP'])\n",
    "            prediction_final_list_2041_2070 = np.mean(predict_list_2041_2070.reshape(num_runs, testing_group_size_pre), axis=0)\n",
    "\n",
    "            # initialize data of lists.\n",
    "            final_list_data_f_2041_2070 = {'id': id_list_2041_2070,'prediction': prediction_final_list_2041_2070}\n",
    "\n",
    "            # Create DataFrame\n",
    "            dataframe_fial_prediction_2041_2070 = pd.DataFrame(final_list_data_f_2041_2070)\n",
    "            \"\"\"change_name\"\"\"\n",
    "            #create a directory for storing the trees\n",
    "            pre_dir_2041_2070 = '/Users/huangliting/Desktop/kissing_bugs_stats/predictions/'+scenario2+'_2041_2070_'+name_for_saving\n",
    "\n",
    "\n",
    "            if not os.path.exists(pre_dir_2041_2070):\n",
    "                os.makedirs(pre_dir_2041_2070)\n",
    "\n",
    "\n",
    "            dataframe_fial_prediction_2041_2070.to_csv( pre_dir_2041_2070+'/'+name_for_saving+'_'+str(num_runs)+'iters.csv')\n",
    "            \n",
    "            \"\"\"\n",
    "            save prediction\n",
    "            \"\"\"\n",
    "\n",
    "            #obtain average prediction list\n",
    "            testing_group_size_pre = len(df_2071_2100['MSP'])\n",
    "            prediction_final_list_2071_2100 = np.mean(predict_list_2071_2100.reshape(num_runs, testing_group_size_pre), axis=0)\n",
    "\n",
    "            # initialize data of lists.\n",
    "            final_list_data_f_2071_2100 = {'id': id_list_2071_2100,'prediction': prediction_final_list_2071_2100}\n",
    "\n",
    "            # Create DataFrame\n",
    "            dataframe_fial_prediction_2071_2100 = pd.DataFrame(final_list_data_f_2071_2100)\n",
    "            \"\"\"change_name\"\"\"\n",
    "            #create a directory for storing the trees\n",
    "            pre_dir_2071_2100 = '/Users/huangliting/Desktop/kissing_bugs_stats/predictions/'+scenario2+'_2071_2100_'+name_for_saving\n",
    "\n",
    "\n",
    "            if not os.path.exists(pre_dir_2071_2100):\n",
    "                os.makedirs(pre_dir_2071_2100)\n",
    "\n",
    "\n",
    "            dataframe_fial_prediction_2071_2100.to_csv( pre_dir_2071_2100+'/'+name_for_saving+'_'+str(num_runs)+'iters.csv')\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
